{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류예측의 불확실성 추정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤 테스트 포인트에 대ㅐ 분류기가 예측한 클래스가 무엇인지 뿐만 아니라 정확한 클래스임을 얼마나 확신하는지 중요할 때가 많다. 실제 어플리케이션에서는 오류의 종류에 따라 전혀 다른 결과를 만든다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn 분류기에는 불확실성을 추정할 수 있는 함수가 두개가 있다. decision_function과 predict_proba이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingClassifier 분류기의 decision_function과 predict_proba 메서드가 어떤 역할을 하는지 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "x,y = make_circles(noise = 0.25, factor =0.5, random_state=1)\n",
    "y_named = np.array(['blue','red'])[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train_named,y_test_named,y_train,y_test = train_test_split(x,y_named,y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=0, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt =GradientBoostingClassifier(random_state=0)\n",
    "gbrt.fit(x_train,y_train_named)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결정함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이진 분류에서 decision function 반환값의 크기는 n_sample이며 각 샘플이 하나의 실수 값을 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 2)\n",
      "[ 4.13592629 -1.7016989  -3.95106099 -3.62599351  4.28986668  3.66166106]\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(gbrt.decision_function(x_test[:6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 값은 모델이 데이터 포인트가 양성 클래스인 1에 속한다고 믿는 정도이다. 양수값은 양성 클래스를 의마하며 음수 값음 음수 클래스를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임계치와 결정 함수 결과 비교:\n",
      "[ True False False False  True  True False  True  True  True False  True\n",
      "  True False  True False False False  True  True  True  True  True False\n",
      " False]\n",
      "예측:\n",
      "['red' 'blue' 'blue' 'blue' 'red' 'red' 'blue' 'red' 'red' 'red' 'blue'\n",
      " 'red' 'red' 'blue' 'red' 'blue' 'blue' 'blue' 'red' 'red' 'red' 'red'\n",
      " 'red' 'blue' 'blue']\n"
     ]
    }
   ],
   "source": [
    "print(\"임계치와 결정 함수 결과 비교:\\n{}\".format(gbrt.decision_function(x_test) > 0))\n",
    "print(\"예측:\\n{}\".format(gbrt.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이진분류에서 음성 클래스는 항상 classes_ 속성의 처 번째 원소이고 양성 클래스는 classes_의 두 번째 원소이다. 그래서 predict 함수의 결과를 완전히 재현하려면 classes_ 속성을 사용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#불리언 값을 0과1로 변환\n",
    "greater_zero = (gbrt.decision_function(x_test) > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['red', 'blue', 'blue', 'blue', 'red', 'red', 'blue', 'red', 'red',\n",
       "       'red', 'blue', 'red', 'red', 'blue', 'red', 'blue', 'blue', 'blue',\n",
       "       'red', 'red', 'red', 'red', 'red', 'blue', 'blue'], \n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = gbrt.classes_[greater_zero]\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred는 예측 결과와 같다: True\n"
     ]
    }
   ],
   "source": [
    "print('pred는 예측 결과와 같다: {}'.format(np.all(pred == gbrt.predict(x_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict_proba의 출력은 각 클래스에 대한 확률이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "확률 값의 형테: (25, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"확률 값의 형테: {}\".format(gbrt.predict_proba(x_test).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 행의 첫 번째 원소는 첫 번째 클래스의 예측 확률이고 두 번째 원소는 두 번쨰 클래스의 예측 확률이다.Predict_proba의 출력은 항상 0과 1사이의 값이며 두 클래스에 대한 확률의 합은 항상1이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측확률:\n",
      "[[ 0.01573626  0.98426374]\n",
      " [ 0.84575649  0.15424351]\n",
      " [ 0.98112869  0.01887131]\n",
      " [ 0.97406775  0.02593225]\n",
      " [ 0.01352142  0.98647858]\n",
      " [ 0.02504637  0.97495363]]\n"
     ]
    }
   ],
   "source": [
    "print(\"예측확률:\\n{}\".format(gbrt.predict_proba(x_test[:6])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 클래스의 확률의 합은 1이므로 두 클래스 중 하나는 50# 이상의 확신을 가질 것이 틀림없다. 그리고 바로 그 클래스가 예측값이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중 분류에서의 불확실성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decision_function과 predict_proba 메서드는 다중 분류에서도 사용할 수 있다. 클래스가 세 개인 iris 데이터셋에 적용해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.01, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=0, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(iris.data,iris.target,random_state = 42)\n",
    "\n",
    "gbrt = GradientBoostingClassifier(learning_rate=0.01,random_state=0)\n",
    "gbrt.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decsion_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정 함수의  결과 형태:(38, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"결정 함수의  결과 형태:{}\".format(gbrt.decision_function(x_test).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정 함수 결과:\n",
      "[[-0.52931069  1.46560359 -0.50448467]\n",
      " [ 1.51154215 -0.49561142 -0.50310736]\n",
      " [-0.52379401 -0.4676268   1.51953786]\n",
      " [-0.52931069  1.46560359 -0.50448467]\n",
      " [-0.53107259  1.28190451  0.21510024]\n",
      " [ 1.51154215 -0.49561142 -0.50310736]]\n"
     ]
    }
   ],
   "source": [
    "print(\"결정 함수 결과:\\n{}\".format(gbrt.decision_function(x_test)[:6,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 열은 각 클래스에 대한 확신 점수를 담고 있다. 수치가 크면 그 클래스일 가능성이 크고 수치가 작으면 그 클래스일 가능성이 낮다는 것이다. 데이터 포인트마다 점수들에서 가장 큰 값을 찾아 예측 결과를 재현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 큰 결정 함수의 인덱스:\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n",
      "예측:\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"가장 큰 결정 함수의 인덱스:\\n{}\".format(np.argmax(gbrt.decision_function(x_test),axis=1)))\n",
    "print(\"예측:\\n{}\".format(gbrt.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측확률:\n",
      "[[ 0.10664722  0.7840248   0.10932798]\n",
      " [ 0.78880668  0.10599243  0.10520089]\n",
      " [ 0.10231173  0.10822274  0.78946553]\n",
      " [ 0.10664722  0.7840248   0.10932798]\n",
      " [ 0.10825347  0.66344934  0.22829719]\n",
      " [ 0.78880668  0.10599243  0.10520089]]\n",
      "합:[ 1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"예측확률:\\n{}\".format(gbrt.predict_proba(x_test)[:6]))\n",
    "print(\"합:{}\".format(gbrt.predict_proba(x_test)[:6].sum(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 큰 예측확률의 인덱스:\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n",
      "에측:\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"가장 큰 예측확률의 인덱스:\\n{}\".format(np.argmax(gbrt.predict_proba(x_test),axis=1)))\n",
    "print(\"에측:\\n{}\".format(gbrt.predict(x_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
